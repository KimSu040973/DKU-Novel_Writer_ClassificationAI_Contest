{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cnn-emb 데모\n",
    "- embedding :: 각 단어를 정수를 인코딩하여 정수를 실수 벡터로 변환하는 것  \n",
    "- 주로 신경망으로 학습하며 층에대한 아웃풋을 그 다음 층의 임베딩(입력)응로 사용하여 학습 \n",
    "\n",
    "## 라이브러리 import 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams, pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPooling1D, Conv1D, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "rcParams['figure.figsize'] = (16, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir    = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\')\n",
    "tst_dir     = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\')\n",
    "feature_dir = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\feature\\\\')\n",
    "sub_dir     = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\sub\\\\')\n",
    "val_dir     = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\val\\\\')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 42\n",
    "\n",
    "algo_name = 'cnn'\n",
    "feature_name = 'emb'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = feature_dir / f'{feature_name}.csv'\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "sub_file = sub_dir / f'{model_name}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  author\n",
       "0      0  He was almost choking. There was so much, so m...       3\n",
       "1      1             “Your sister asked for it, I suppose?”       2\n",
       "2      2   She was engaged one day as she walked, in per...       1\n",
       "3      3  The captain was in the porch, keeping himself ...       4\n",
       "4      4  “Have mercy, gentlemen!” odin flung up his han...       3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(trn_file, encoding = 'utf-8')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>“Not at all. I think she is one of the most ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>As the lady had stated her intention of scream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>“And then suddenly in the silence I heard a so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>His conviction remained unchanged. So far as I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      0  “Not at all. I think she is one of the most ch...\n",
       "1      1  \"No,\" replied he, with sudden consciousness, \"...\n",
       "2      2  As the lady had stated her intention of scream...\n",
       "3      3  “And then suddenly in the silence I heard a so...\n",
       "4      4  His conviction remained unchanged. So far as I..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(tst_file, encoding = 'utf-8')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#부호를 제거해주는 함수\n",
    "def alpha_num(text):\n",
    "    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n",
    "\n",
    "# 불용어 제거해주는 함수\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stopwords:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "# 불용어\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n",
    "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
    "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
    "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
    "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
    "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
    "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
    "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
    "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
    "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
    "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 적용\n",
    "train['text'] = train['text'].str.lower()\n",
    "test['text'] = test['text'].str.lower()\n",
    "train['text'] = train['text'].apply(alpha_num).apply(remove_stopwords)\n",
    "test['text'] = test['text'].apply(alpha_num).apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879,) (19617,) (54879,)\n"
     ]
    }
   ],
   "source": [
    "# train test 분리\n",
    "X_train = train['text'].values\n",
    "X_test = test['text'].values\n",
    "y = train['author'].values\n",
    "print(X_train.shape, X_test.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['almost choking much much wanted say strange exclamations came lips pole gazed fixedly bundle notes hand looked odin evident perplexity',\n",
       "       'sister asked suppose',\n",
       "       'engaged one day walked perusing janes last letter dwelling passages proved jane not written spirits instead surprised mr odin saw looking odin meeting putting away letter immediately forcing smile said'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- 보통 미리 학습된 임베딩 오픈소스 사용-->장점:단어수 (데이터량)에 영향 받지 않고 다양한 단어, 많은 단어로 학습 진행가능\n",
    "- 추가로 보통 오픈소스 300개 유의미 한 관계추출 가능 적은 데이터 만으로도 무게는 고정하여 나머지 측의 무게를 변환하여 학습 가능\n",
    "1. word3vec by google 두개 다른 뉴런 네트워크 구조를 사용 \n",
    "2. fastText by facebook 단어 개수를 가지고 나눌때 단위를 단순ㅅ 수가 아닌 캐릭터 단위로 나누어 범주를 만듬\n",
    "3. GloVe by Stanford 자주 출현한 빈도를 계산하는 것을 도와줌(강사님 추천!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 설정\n",
    "vocab_size = 20000\n",
    "embedding_dim = 64 \n",
    "max_length = 500\n",
    "padding_type='post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer에 fit\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터를 sequence로 변환해주고 padding\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 500) (19617, 500)\n"
     ]
    }
   ],
   "source": [
    "trn = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
    "tst = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
    "print(trn.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross Validation\n",
    "*Stratified N-Fold CV: N-Fold CV에서 각각의 폴드에서 종속변수의 분포가 동일하도록 폴드를 나누는 방식.\n",
    "현재 사용하는 데이터처럼 분류학습에서 종속변수의 범주의 분포가 균일하지 않을 때 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#가벼운 NLP모델 생성\n",
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        Dropout(.5),\n",
    "        Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3),\n",
    "        Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3),    \n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(.5),\n",
    "        Dense(n_class, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=.0003))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 106s 77ms/step - loss: 1.4698 - val_loss: 1.2688\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 111s 81ms/step - loss: 1.1108 - val_loss: 0.9706\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 116s 84ms/step - loss: 0.8542 - val_loss: 0.8316\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 117s 85ms/step - loss: 0.6798 - val_loss: 0.7926\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 115s 84ms/step - loss: 0.5724 - val_loss: 0.7738\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 105s 76ms/step - loss: 0.4960 - val_loss: 0.7751\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 113s 82ms/step - loss: 0.4384 - val_loss: 0.7848\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - ETA: 0s - loss: 0.3994- ETA: 0s - loss: 0.3Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1372/1372 [==============================] - 152s 111ms/step - loss: 0.3994 - val_loss: 0.8247\n",
      "Epoch 00008: early stopping\n",
      "training model for CV #2\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 170s 124ms/step - loss: 1.4756 - val_loss: 1.3056\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 151s 110ms/step - loss: 1.1246 - val_loss: 0.9735\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 138s 100ms/step - loss: 0.8424 - val_loss: 0.8312\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 108s 79ms/step - loss: 0.6813 - val_loss: 0.8001\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 109s 79ms/step - loss: 0.5861 - val_loss: 0.7919\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 112s 82ms/step - loss: 0.5170 - val_loss: 0.8094\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 114s 83ms/step - loss: 0.4651 - val_loss: 0.8132\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - ETA: 0s - loss: 0.4162Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1372/1372 [==============================] - 114s 83ms/step - loss: 0.4162 - val_loss: 0.8251\n",
      "Epoch 00008: early stopping\n",
      "training model for CV #3\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 116s 85ms/step - loss: 1.4712 - val_loss: 1.3145\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 119s 87ms/step - loss: 1.1840 - val_loss: 1.0073\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 126s 91ms/step - loss: 0.8765 - val_loss: 0.8234\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 122s 89ms/step - loss: 0.7051 - val_loss: 0.7774\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 125s 91ms/step - loss: 0.5951 - val_loss: 0.7709\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 123s 90ms/step - loss: 0.5177 - val_loss: 0.7765\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 128s 94ms/step - loss: 0.4577 - val_loss: 0.7955\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - ETA: 0s - loss: 0.4143Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1372/1372 [==============================] - 128s 93ms/step - loss: 0.4143 - val_loss: 0.8113\n",
      "Epoch 00008: early stopping\n",
      "training model for CV #4\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 121s 88ms/step - loss: 1.4560 - val_loss: 1.2021\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 128s 93ms/step - loss: 1.0571 - val_loss: 0.9404\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 121s 88ms/step - loss: 0.8353 - val_loss: 0.8453\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 119s 87ms/step - loss: 0.6957 - val_loss: 0.8058\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 120s 87ms/step - loss: 0.5961 - val_loss: 0.7905\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 118s 86ms/step - loss: 0.5273 - val_loss: 0.8090\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 120s 88ms/step - loss: 0.4682 - val_loss: 0.8134\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - ETA: 0s - loss: 0.4190Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1372/1372 [==============================] - 118s 86ms/step - loss: 0.4190 - val_loss: 0.8231\n",
      "Epoch 00008: early stopping\n",
      "training model for CV #5\n",
      "Epoch 1/10\n",
      "1372/1372 [==============================] - 117s 85ms/step - loss: 1.4840 - val_loss: 1.2918\n",
      "Epoch 2/10\n",
      "1372/1372 [==============================] - 115s 84ms/step - loss: 1.0955 - val_loss: 0.9393\n",
      "Epoch 3/10\n",
      "1372/1372 [==============================] - 113s 82ms/step - loss: 0.8320 - val_loss: 0.8132\n",
      "Epoch 4/10\n",
      "1372/1372 [==============================] - 115s 84ms/step - loss: 0.6859 - val_loss: 0.7764\n",
      "Epoch 5/10\n",
      "1372/1372 [==============================] - 114s 83ms/step - loss: 0.5967 - val_loss: 0.7611\n",
      "Epoch 6/10\n",
      "1372/1372 [==============================] - 114s 83ms/step - loss: 0.5234 - val_loss: 0.7695\n",
      "Epoch 7/10\n",
      "1372/1372 [==============================] - 115s 84ms/step - loss: 0.4712 - val_loss: 0.7798\n",
      "Epoch 8/10\n",
      "1372/1372 [==============================] - ETA: 0s - loss: 0.4187Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "1372/1372 [==============================] - 116s 84ms/step - loss: 0.4187 - val_loss: 0.7988\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fit model & predict values\n",
    "p_val = np.zeros((trn.shape[0], n_class))\n",
    "p_tst = np.zeros((tst.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    clf = get_model()\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3,\n",
    "                       verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
    "\n",
    "    rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                            patience=3, min_lr=1e-6, mode='min', verbose=1)\n",
    "\n",
    "    clf.fit(trn[i_trn], \n",
    "            to_categorical(y[i_trn]),\n",
    "            validation_data=(trn[i_val], to_categorical(y[i_val])),\n",
    "            epochs=10,\n",
    "            callbacks=[es, rlr])\n",
    "    p_val[i_val, :] = clf.predict(trn[i_val])\n",
    "    p_tst += clf.predict(tst) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CV):  71.5264%\n",
      "Log Loss (CV):   0.7777\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p_val, axis=1)) * 100:8.4f}%')\n",
    "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p_val):8.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 64)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 165, 128)          57472     \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 53, 128)           114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,469,445\n",
      "Trainable params: 1,469,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "print(clf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19617, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4\n",
       "index               \n",
       "0      0  0  0  0  0\n",
       "1      0  0  0  0  0\n",
       "2      0  0  0  0  0\n",
       "3      0  0  0  0  0\n",
       "4      0  0  0  0  0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(sample_file, index_col=0)\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.5989</td>\n",
       "      <td>1.0766e-01</td>\n",
       "      <td>2.2232e-01</td>\n",
       "      <td>0.0287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.5356</td>\n",
       "      <td>4.9047e-02</td>\n",
       "      <td>3.7313e-02</td>\n",
       "      <td>0.1865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9987</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>1.2554e-05</td>\n",
       "      <td>7.0363e-06</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>7.8165e-01</td>\n",
       "      <td>3.4634e-04</td>\n",
       "      <td>0.2169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>6.9613e-02</td>\n",
       "      <td>4.8803e-02</td>\n",
       "      <td>0.1410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2           3       4\n",
       "index                                                \n",
       "0      0.0424  0.5989  1.0766e-01  2.2232e-01  0.0287\n",
       "1      0.1915  0.5356  4.9047e-02  3.7313e-02  0.1865\n",
       "2      0.9987  0.0008  1.2554e-05  7.0363e-06  0.0005\n",
       "3      0.0009  0.0003  7.8165e-01  3.4634e-04  0.2169\n",
       "4      0.7184  0.0222  6.9613e-02  4.8803e-02  0.1410"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[sub.columns] = p_tst\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(sub_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
