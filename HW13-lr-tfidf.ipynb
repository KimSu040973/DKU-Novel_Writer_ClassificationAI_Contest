{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lr-tfidf데모"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 import 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "rcParams['figure.figsize'] = (16, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir    = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\')\n",
    "tst_dir     = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\')\n",
    "feature_dir = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\feature\\\\')\n",
    "sub_dir     = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\sub\\\\')\n",
    "val_dir     = Path('C:\\\\Users\\\\USER\\\\Desktop\\\\open\\\\val\\\\')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test_x.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'author'\n",
    "n_fold = 5\n",
    "n_class = 5\n",
    "seed = 42\n",
    "\n",
    "algo_name = 'lr'\n",
    "feature_name = 'tfidf'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = feature_dir / f'{feature_name}.csv'\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "sub_file = sub_dir / f'{model_name}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "index                                                           \n",
       "0      He was almost choking. There was so much, so m...       3\n",
       "1                 “Your sister asked for it, I suppose?”       2\n",
       "2       She was engaged one day as she walked, in per...       1\n",
       "3      The captain was in the porch, keeping himself ...       4\n",
       "4      “Have mercy, gentlemen!” odin flung up his han...       3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn = pd.read_csv(trn_file, index_col=0)\n",
    "print(trn.shape)\n",
    "trn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19617, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Not at all. I think she is one of the most ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"No,\" replied he, with sudden consciousness, \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As the lady had stated her intention of scream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“And then suddenly in the silence I heard a so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His conviction remained unchanged. So far as I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "index                                                   \n",
       "0      “Not at all. I think she is one of the most ch...\n",
       "1      \"No,\" replied he, with sudden consciousness, \"...\n",
       "2      As the lady had stated her intention of scream...\n",
       "3      “And then suddenly in the silence I heard a so...\n",
       "4      His conviction remained unchanged. So far as I..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = pd.read_csv(tst_file, index_col=0)\n",
    "print(tst.shape)\n",
    "tst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK 예시_전처리\n",
    "* 자연어 처리(NLP) 를 위한 자연어 라이브러리(nltk,spacy) 중 하나\n",
    "* 피처 가공에 따라 라이브러리 달리할 것.\n",
    "* EX> spacy에서 전처리와 피처가공 툴을 같이 제공하기 때문에 추가로 피처가공 틀인 sklearn or keras 필요X\n",
    "* EX> NLTK 로 전처리과정을 거치고 다른 피처 가공 툴 사용도 가능 \n",
    "* 피처가공처리의 필요도가 낮은 알고리즘, 신경망 사용으로 자연어처리할 경우 가공단계 필요 X \n",
    "* Tokenizer, Lemmatization, Stemming.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“Have mercy, gentlemen!” odin flung up his hands. “Don’t write that, anyway; have some shame. Here I’ve torn my heart asunder before you, and you seize the opportunity and are fingering the wounds in both halves.... Oh, my God!”\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s = trn.text[4]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“', 'Have', 'mercy', ',', 'gentlemen', '!', '”', 'odin', 'flung', 'up', 'his', 'hands', '.', '“', 'Don', '’', 't', 'write', 'that', ',', 'anyway', ';', 'have', 'some', 'shame', '.', 'Here', 'I', '’', 've', 'torn', 'my', 'heart', 'asunder', 'before', 'you', ',', 'and', 'you', 'seize', 'the', 'opportunity', 'and', 'are', 'fingering', 'the', 'wounds', 'in', 'both', 'halves', '....', 'Oh', ',', 'my', 'God', '!', '”']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(s)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“',\n",
       " 'Have',\n",
       " 'mercy',\n",
       " ',',\n",
       " 'gentleman',\n",
       " '!',\n",
       " '”',\n",
       " 'odin',\n",
       " 'flung',\n",
       " 'up',\n",
       " 'his',\n",
       " 'hand',\n",
       " '.',\n",
       " '“',\n",
       " 'Don',\n",
       " '’',\n",
       " 't',\n",
       " 'write',\n",
       " 'that',\n",
       " ',',\n",
       " 'anyway',\n",
       " ';',\n",
       " 'have',\n",
       " 'some',\n",
       " 'shame',\n",
       " '.',\n",
       " 'Here',\n",
       " 'I',\n",
       " '’',\n",
       " 've',\n",
       " 'torn',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'asunder',\n",
       " 'before',\n",
       " 'you',\n",
       " ',',\n",
       " 'and',\n",
       " 'you',\n",
       " 'seize',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'and',\n",
       " 'are',\n",
       " 'fingering',\n",
       " 'the',\n",
       " 'wound',\n",
       " 'in',\n",
       " 'both',\n",
       " 'half',\n",
       " '....',\n",
       " 'Oh',\n",
       " ',',\n",
       " 'my',\n",
       " 'God',\n",
       " '!',\n",
       " '”']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#언어학적으로 상세한 규칙을 적용하여 변환\n",
    "#대소문자는 그대로, 단복수는 복수로 변환 \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "[lemmatizer.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“',\n",
       " 'have',\n",
       " 'merci',\n",
       " ',',\n",
       " 'gentlemen',\n",
       " '!',\n",
       " '”',\n",
       " 'odin',\n",
       " 'flung',\n",
       " 'up',\n",
       " 'his',\n",
       " 'hand',\n",
       " '.',\n",
       " '“',\n",
       " 'don',\n",
       " '’',\n",
       " 't',\n",
       " 'write',\n",
       " 'that',\n",
       " ',',\n",
       " 'anyway',\n",
       " ';',\n",
       " 'have',\n",
       " 'some',\n",
       " 'shame',\n",
       " '.',\n",
       " 'here',\n",
       " 'i',\n",
       " '’',\n",
       " 've',\n",
       " 'torn',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'asund',\n",
       " 'befor',\n",
       " 'you',\n",
       " ',',\n",
       " 'and',\n",
       " 'you',\n",
       " 'seiz',\n",
       " 'the',\n",
       " 'opportun',\n",
       " 'and',\n",
       " 'are',\n",
       " 'finger',\n",
       " 'the',\n",
       " 'wound',\n",
       " 'in',\n",
       " 'both',\n",
       " 'halv',\n",
       " '....',\n",
       " 'oh',\n",
       " ',',\n",
       " 'my',\n",
       " 'god',\n",
       " '!',\n",
       " '”']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위보다 빠르고 성능도 비슷\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "[stemmer.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[문자열 가공]  \n",
    "1. Bag-of-Words(simple):countVectorizer, TfidVectorizer  \n",
    "2. Hashing Trick: hashingVectorizer  \n",
    "3. Embeddings(with 신경망): Word2Vec, GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words 피처 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 2685) (19617, 1920)\n"
     ]
    }
   ],
   "source": [
    "#각 단어의 빈도를 피처로 사용\n",
    "#생성 피처 조절(필수):mon_df,max_feature\n",
    "vec = CountVectorizer(tokenizer=word_tokenize, stop_words=stopwords.words('english'), ngram_range=(1, 2), min_df=100)\n",
    "X_cnt = vec.fit_transform(trn['text'])\n",
    "X_tst = vec.fit_transform(tst['text'])\n",
    "print(X_cnt.shape,X_tst.shape)#열 크기 같게 만들어줘야함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0에 집중되어 있는 멱함수 분포를 뜀\n",
    "#->로지스틱 회귀 도는 뉴럴 네트워크 알고리즘과 같이 사용하여 정규화 과정이 필요\n",
    "X_cnt[0, :50].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 5897) (19617, 5897)\n"
     ]
    }
   ],
   "source": [
    "#정규화 또는 표준화 과정없이 피처 생성 툴\n",
    "#각단어의 빈도를 역문서 빈도로 나눈 값을 피처로 사용\n",
    "vec = TfidfVectorizer(tokenizer=word_tokenize, stop_words=stopwords.words('english'), ngram_range=(1, 3), min_df=50)\n",
    "X = vec.fit_transform(trn['text'])\n",
    "X_tst = vec.transform(tst['text'])\n",
    "print(X.shape, X_tst.shape)\n",
    "#학습에 적용할때\n",
    "#가공한 X,X_tst 변수의 경우 형태가 numpy와 비슷하여 sklearn에 바로 적용가능+lgbm, xgboost ok\n",
    "#그러나 파이토치(pytorch),텐서플로,keras, 뉴럴Network 신경망 적용시 \"\".todense()\"\" 함수로 변환과정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, :50].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing Trick 피처 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54879, 7)\n",
      "[[-0.6644106   0.5694948   0.1898316  ... -0.0949158  -0.1898316\n",
      "  -0.3796632 ]\n",
      " [-0.19611614 -0.78446454 -0.39223227 ... -0.19611614  0.\n",
      "   0.        ]\n",
      " [-0.1933473  -0.67671554  0.3866946  ...  0.58004189 -0.09667365\n",
      "   0.        ]\n",
      " ...\n",
      " [-0.56011203 -0.28005602  0.56011203 ...  0.28005602 -0.14002801\n",
      "   0.14002801]\n",
      " [-0.24253563 -0.24253563 -0.24253563 ...  0.          0.72760688\n",
      "  -0.24253563]\n",
      " [ 0.34299717 -0.51449576 -0.51449576 ... -0.17149859  0.17149859\n",
      "  -0.51449576]]\n"
     ]
    }
   ],
   "source": [
    "#Hashing Trick:각각 범주를 Hash함수에 적용한 값으로 변환\n",
    "#->fit() 필요X fast low memory\n",
    "vectorize = HashingVectorizer(tokenizer=word_tokenize, stop_words=stopwords.words('english'), ngram_range=(1, 3),\n",
    "    n_features=7               # 기본 feature 수를 설정하며 기본값이 2의 20승이다. 아래 예시를 위해 feature 를 7로 한정했으나, 아래 유사문장을 찾을때는 다시 n_features 주석처리 했다.\n",
    ")\n",
    "X_hv = vectorize.fit_transform(trn['text'])\n",
    "print(X_hv.shape)\n",
    "print(X_hv.toarray())#todense()처럼 변환하여 0과 값을 같이 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가로 back of word or hashing 의 경우 문자열 길이 통합을 위한 padding 작업X\n",
    "# 문자열 입력을 자체로 받는 경우 padding 요구 EX> 뉴럴네트워크 에서의 문자모델링에서 요구함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold Cross Validation\n",
    "*Stratified N-Fold CV: N-Fold CV에서 각각의 폴드에서 종속변수의 분포가 동일하도록 폴드를 나누는 방식.\n",
    "현재 사용하는 데이터처럼 분류학습에서 종속변수의 범주의 분포가 균일하지 않을 때 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱회귀 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trn.author.values\n",
    "y.shape\n",
    "p = np.zeros((X.shape[0], n_class))\n",
    "p_tst = np.zeros((X_tst.shape[0], n_class))\n",
    "for i_cv, (i_trn, i_val) in enumerate(cv.split(X, y), 1):\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X[i_trn], y[i_trn])\n",
    "    p[i_val, :] = clf.predict_proba(X[i_val])\n",
    "    p_tst += clf.predict_proba(X_tst) / n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CV):  76.6140%\n",
      "Log Loss (CV):   0.6800\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy (CV): {accuracy_score(y, np.argmax(p, axis=1)) * 100:8.4f}%')\n",
    "print(f'Log Loss (CV): {log_loss(pd.get_dummies(y), p):8.4f}')#리더보드_0.5052060884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(p_val_file, p, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19617, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4\n",
       "index               \n",
       "0      0  0  0  0  0\n",
       "1      0  0  0  0  0\n",
       "2      0  0  0  0  0\n",
       "3      0  0  0  0  0\n",
       "4      0  0  0  0  0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(sample_file, index_col=0)\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.0253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7208</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.1161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4\n",
       "index                                        \n",
       "0      0.0631  0.5302  0.3155  0.0659  0.0253\n",
       "1      0.0815  0.8202  0.0032  0.0269  0.0682\n",
       "2      0.7208  0.0319  0.1174  0.0381  0.0918\n",
       "3      0.0392  0.0036  0.8465  0.0058  0.1049\n",
       "4      0.3044  0.2440  0.1450  0.1905  0.1161"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[sub.columns] = p_tst\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(sub_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
