{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model, Input\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Dropout,Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>He was almost choking. There was so much, so m...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>“Your sister asked for it, I suppose?”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>She was engaged one day as she walked, in per...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The captain was in the porch, keeping himself ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54874</th>\n",
       "      <td>54874</td>\n",
       "      <td>“Is that you, Mr. Smith?” odin whispered. “I h...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54875</th>\n",
       "      <td>54875</td>\n",
       "      <td>I told my plan to the captain, and between us ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54876</th>\n",
       "      <td>54876</td>\n",
       "      <td>\"Your sincere well-wisher, friend, and sister...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54877</th>\n",
       "      <td>54877</td>\n",
       "      <td>“Then you wanted me to lend you money?”</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54878</th>\n",
       "      <td>54878</td>\n",
       "      <td>It certainly had not occurred to me before, bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54879 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                               text  author\n",
       "0          0  He was almost choking. There was so much, so m...       3\n",
       "1          1             “Your sister asked for it, I suppose?”       2\n",
       "2          2   She was engaged one day as she walked, in per...       1\n",
       "3          3  The captain was in the porch, keeping himself ...       4\n",
       "4          4  “Have mercy, gentlemen!” odin flung up his han...       3\n",
       "...      ...                                                ...     ...\n",
       "54874  54874  “Is that you, Mr. Smith?” odin whispered. “I h...       2\n",
       "54875  54875  I told my plan to the captain, and between us ...       4\n",
       "54876  54876   \"Your sincere well-wisher, friend, and sister...       1\n",
       "54877  54877            “Then you wanted me to lend you money?”       3\n",
       "54878  54878  It certainly had not occurred to me before, bu...       0\n",
       "\n",
       "[54879 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(predictions,target):\n",
    "    '''\n",
    "    This methods returns the AUC Score when given the Predictions\n",
    "    and Labels\n",
    "    '''\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, train.author.values, \n",
    "                                                  stratify=train.author.values, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = Tokenizer(num_words=None)\n",
    "max_len = 1500\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "#zero pad the sequences\n",
    "xtrain_pad = pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].str.lower()\n",
    "test['text'] = test['text'].str.lower()\n",
    "X_train = train['text'].values\n",
    "X_test = test['text'].values\n",
    "y = train['author'].values\n",
    "\n",
    "tokenizer = Tokenizer(num_words = None)\n",
    "max_len = 1500\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "#zero pad the sequences\n",
    "trn = pad_sequences(train_sequences,maxlen=max_len)\n",
    "tst = pad_sequences(test_sequences, maxlen=max_len)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:37, 10608.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe vectors in a dictionary:\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('./data/glove.6B.300d.txt','r',encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray([float(val) for val in values[1:]])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42330/42330 [00:00<00:00, 205371.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1500, 300)         12699300  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 12,860,205\n",
      "Trainable params: 160,905\n",
      "Non-trainable params: 12,699,300\n",
      "_________________________________________________________________\n",
      "CPU times: user 428 ms, sys: 380 ms, total: 808 ms\n",
      "Wall time: 664 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    \n",
    "    # A simple LSTM with glove embeddings and one dense layer\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "\n",
    "    model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "    model.add(Dense(5, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "ytrain= to_categorical (ytrain)\n",
    "yvalid= to_categorical (yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "686/686 [==============================] - 1882s 3s/step - loss: 0.4281 - accuracy: 0.4504\n",
      "Epoch 2/5\n",
      "686/686 [==============================] - 1885s 3s/step - loss: 0.3668 - accuracy: 0.5563\n",
      "Epoch 3/5\n",
      "686/686 [==============================] - 1882s 3s/step - loss: 0.3365 - accuracy: 0.6006\n",
      "Epoch 4/5\n",
      "686/686 [==============================] - 1882s 3s/step - loss: 0.3133 - accuracy: 0.6362\n",
      "Epoch 5/5\n",
      "686/686 [==============================] - 1874s 3s/step - loss: 0.2965 - accuracy: 0.6606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f906f6a8bb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, ytrain, epochs=5, batch_size=64*strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(xvalid_pad)\n",
    "print(\"Auc: %.4f%%\" % (roc_auc(scores,yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tst = model.predict(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./data/sample_submission.csv', index_col=0)\n",
    "sub[sub.columns] = p_tst\n",
    "sub.to_csv('ZerotoTransLstm1.csv')#0.7768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "858/858 [==============================] - 2393s 3s/step - loss: 0.3854 - accuracy: 0.5293\n",
      "Epoch 2/5\n",
      "858/858 [==============================] - 2372s 3s/step - loss: 0.3156 - accuracy: 0.6373\n",
      "Epoch 3/5\n",
      "858/858 [==============================] - 2378s 3s/step - loss: 0.2831 - accuracy: 0.6818\n",
      "Epoch 4/5\n",
      "858/858 [==============================] - 2361s 3s/step - loss: 0.2618 - accuracy: 0.7084\n",
      "Epoch 5/5\n",
      "858/858 [==============================] - 2363s 3s/step - loss: 0.2461 - accuracy: 0.7303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f11cb0a3f10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn, to_categorical(y), epochs=5, batch_size = 64*strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tst = model.predict(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./data/sample_submission.csv', index_col=0)\n",
    "sub[sub.columns] = p_tst\n",
    "sub.to_csv('ZerotoTransLstm2.csv')#0.563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
